1:"$Sreact.fragment"
3:I[283,["2992","static/chunks/bc9e92e6-1c042a4cb7f7ee91.js","9507","static/chunks/457b8330-4b761ccea66ed9aa.js","7158","static/chunks/aa35ee89-a2c5fbd77e3fd8af.js","6874","static/chunks/6874-e99f1ffdde1ee6c4.js","883","static/chunks/883-1c432fd5a9417496.js","283","static/chunks/283-5caa64571be82a90.js","7177","static/chunks/app/layout-c6fdd31ec17bd76a.js"],"AuthProvider"]
4:I[4126,["2992","static/chunks/bc9e92e6-1c042a4cb7f7ee91.js","9507","static/chunks/457b8330-4b761ccea66ed9aa.js","7158","static/chunks/aa35ee89-a2c5fbd77e3fd8af.js","6874","static/chunks/6874-e99f1ffdde1ee6c4.js","883","static/chunks/883-1c432fd5a9417496.js","283","static/chunks/283-5caa64571be82a90.js","7177","static/chunks/app/layout-c6fdd31ec17bd76a.js"],"AdminProvider"]
5:I[7450,["2992","static/chunks/bc9e92e6-1c042a4cb7f7ee91.js","9507","static/chunks/457b8330-4b761ccea66ed9aa.js","7158","static/chunks/aa35ee89-a2c5fbd77e3fd8af.js","6874","static/chunks/6874-e99f1ffdde1ee6c4.js","883","static/chunks/883-1c432fd5a9417496.js","283","static/chunks/283-5caa64571be82a90.js","7177","static/chunks/app/layout-c6fdd31ec17bd76a.js"],"default"]
6:I[1970,["2992","static/chunks/bc9e92e6-1c042a4cb7f7ee91.js","9507","static/chunks/457b8330-4b761ccea66ed9aa.js","7158","static/chunks/aa35ee89-a2c5fbd77e3fd8af.js","6874","static/chunks/6874-e99f1ffdde1ee6c4.js","883","static/chunks/883-1c432fd5a9417496.js","283","static/chunks/283-5caa64571be82a90.js","7177","static/chunks/app/layout-c6fdd31ec17bd76a.js"],"default"]
7:I[7555,[],""]
8:I[1295,[],""]
9:I[6821,["2992","static/chunks/bc9e92e6-1c042a4cb7f7ee91.js","9507","static/chunks/457b8330-4b761ccea66ed9aa.js","7158","static/chunks/aa35ee89-a2c5fbd77e3fd8af.js","6874","static/chunks/6874-e99f1ffdde1ee6c4.js","883","static/chunks/883-1c432fd5a9417496.js","283","static/chunks/283-5caa64571be82a90.js","7177","static/chunks/app/layout-c6fdd31ec17bd76a.js"],"default"]
b:I[9665,[],"MetadataBoundary"]
d:I[9665,[],"OutletBoundary"]
10:I[4911,[],"AsyncMetadataOutlet"]
12:I[9665,[],"ViewportBoundary"]
14:I[6614,[],""]
:HL["/_next/static/css/f30152c0704fba31.css","style"]
:HL["/_next/static/css/4e6a86ce4da87928.css","style"]
:HL["/_next/static/css/09dfadb69bdaa005.css","style"]
2:T90b,
            // Hide any Firebase configuration check messages
            (function() {
              // Text to hide
              const textToHide = 'Kiểm tra cấu hình Firebase';

              // Function to hide Firebase messages
              function hideFirebaseMessages() {
                // Add a class to the body
                if (document.body) {
                  document.body.classList.add('firebase-messages-hidden');
                }

                // Simple approach: hide any element containing the text
                const allElements = document.querySelectorAll('*');
                allElements.forEach(function(el) {
                  if (el.textContent && el.textContent.includes(textToHide)) {
                    el.style.display = 'none';
                  }
                });

                // Also hide elements with data attribute
                const dataElements = document.querySelectorAll('[data-firebase-config-check]');
                dataElements.forEach(function(el) {
                  el.style.display = 'none';
                });
              }

              // Run immediately if possible
              if (document.readyState !== 'loading') {
                hideFirebaseMessages();
              } else {
                document.addEventListener('DOMContentLoaded', hideFirebaseMessages);
              }

              // Also run on load
              window.addEventListener('load', hideFirebaseMessages);

              // Set up interval to keep checking
              setInterval(hideFirebaseMessages, 1000);

              // Set up MutationObserver for dynamic content
              if (typeof MutationObserver !== 'undefined') {
                const observer = new MutationObserver(hideFirebaseMessages);

                // Start observing when body is available
                function setupObserver() {
                  if (document.body) {
                    observer.observe(document.body, {
                      childList: true,
                      subtree: true,
                      characterData: true
                    });
                  } else {
                    setTimeout(setupObserver, 100);
                  }
                }

                setupObserver();
              }
            })();
          0:{"P":null,"b":"2VP04QkNGi4YZX3VS0ew6","p":"","c":["","publications","multi-scale-and-multi-level-attention-based-on-external-knowledge-in-ehrs"],"i":false,"f":[[["",{"children":["publications",{"children":[["slug","multi-scale-and-multi-level-attention-based-on-external-knowledge-in-ehrs","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/f30152c0704fba31.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/4e6a86ce4da87928.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":["$","script",null,{"dangerouslySetInnerHTML":{"__html":"$2"}}]}],["$","body",null,{"className":"__variable_5cfdac __variable_9a8899 antialiased","style":{"backgroundColor":"#0a0a0a","color":"#ededed","visibility":"visible","display":"block"},"children":["$","$L3",null,{"children":["$","$L4",null,{"children":["$","$L5",null,{"children":["$","div",null,{"id":"app-content","style":{"minHeight":"100vh","display":"flex","flexDirection":"column"},"children":[["$","$L6",null,{}],["$","main",null,{"style":{"flex":"1 1 auto"},"children":["$","$L7",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L9",null,{}]]}]}]}]}]}]]}]]}],{"children":["publications",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","multi-scale-and-multi-level-attention-based-on-external-knowledge-in-ehrs","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",["$","$Lb",null,{"children":"$Lc"}],[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/09dfadb69bdaa005.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$Ld",null,{"children":["$Le","$Lf",["$","$L10",null,{"promise":"$@11"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","PeBsGybulNnXFLraHy_ji",{"children":[["$","$L12",null,{"children":"$L13"}],null]}],null]}],false]],"m":"$undefined","G":["$14","$undefined"],"s":false,"S":true}
15:"$Sreact.suspense"
16:I[4911,[],"AsyncMetadata"]
c:["$","$15",null,{"fallback":null,"children":["$","$L16",null,{"promise":"$@17"}]}]
f:null
13:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
e:null
17:{"metadata":[["$","title","0",{"children":"Duc Le | Personal Portfolio"}],["$","meta","1",{"name":"description","content":"Welcome to my personal portfolio showcasing my projects, publications, and professional journey."}],["$","meta","2",{"name":"author","content":"Duc Le"}],["$","meta","3",{"name":"keywords","content":"portfolio,developer,projects,publications,personal website"}],["$","meta","4",{"property":"og:title","content":"Duc Le | Personal Portfolio"}],["$","meta","5",{"property":"og:description","content":"Welcome to my personal portfolio showcasing my projects, publications, and professional journey."}],["$","meta","6",{"property":"og:url","content":"https://your-domain.com"}],["$","meta","7",{"property":"og:site_name","content":"Duc Le Portfolio"}],["$","meta","8",{"property":"og:locale","content":"en_US"}],["$","meta","9",{"property":"og:type","content":"website"}],["$","meta","10",{"name":"twitter:card","content":"summary"}],["$","meta","11",{"name":"twitter:title","content":"Duc Le | Personal Portfolio"}],["$","meta","12",{"name":"twitter:description","content":"Welcome to my personal portfolio showcasing my projects, publications, and professional journey."}],["$","link","13",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}]],"error":null,"digest":"$undefined"}
11:{"metadata":"$17:metadata","error":null,"digest":"$undefined"}
18:I[7190,["7330","static/chunks/d3ac728e-380f4062b213d721.js","6874","static/chunks/6874-e99f1ffdde1ee6c4.js","2932","static/chunks/app/publications/%5Bslug%5D/page-ef6de94f25993248.js"],"default"]
19:I[9228,["7330","static/chunks/d3ac728e-380f4062b213d721.js","6874","static/chunks/6874-e99f1ffdde1ee6c4.js","2932","static/chunks/app/publications/%5Bslug%5D/page-ef6de94f25993248.js"],"default"]
a:["$","main",null,{"className":"container mx-auto px-4 py-12","children":["$","article",null,{"className":"max-w-3xl mx-auto bg-white dark:bg-gray-800 rounded-lg shadow-md p-8 border border-gray-200 dark:border-gray-700","children":[["$","h1",null,{"className":"text-3xl md:text-4xl font-bold mb-3 text-gray-900 dark:text-white","children":"Multi-scale and Multi-level Attention based on External knowledge in EHRs"}],["$","p",null,{"className":"text-md text-gray-600 dark:text-gray-400 mb-2","children":"Duc Le, Bac Le"}],["$","p",null,{"className":"text-sm text-gray-500 dark:text-gray-400 italic mb-6","children":["Asian Conference on Intelligent Information and Database Systems",", ","2024-04-01",["$","span",null,{"className":"ml-2 font-medium","children":["[","B","]"]}],null]}],["$","div",null,{"className":"mb-6 bg-yellow-50 dark:bg-yellow-900/20 border-l-4 border-yellow-500 p-4 rounded shadow-sm","children":[["$","h3",null,{"className":"font-semibold text-yellow-800 dark:text-yellow-200 text-sm mb-1","children":"HIGHLIGHT"}],["$","p",null,{"className":"text-yellow-800 dark:text-yellow-200 font-medium","children":"Proposes a multi-level, multi-scale attention model incorporating external knowledge to improve risk prediction tasks on EHRs."}]]}],["$","div",null,{"className":"mb-6","children":[["$","h3",null,{"className":"font-semibold text-gray-700 dark:text-gray-300 text-sm mb-2","children":"TOPICS"}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","Healthcare AI",{"className":"bg-blue-100 text-blue-800 text-xs font-medium px-2.5 py-0.5 rounded dark:bg-blue-900 dark:text-blue-300","children":"Healthcare AI"}],["$","span","Predictive Modeling",{"className":"bg-blue-100 text-blue-800 text-xs font-medium px-2.5 py-0.5 rounded dark:bg-blue-900 dark:text-blue-300","children":"Predictive Modeling"}],["$","span","Deep Learning",{"className":"bg-blue-100 text-blue-800 text-xs font-medium px-2.5 py-0.5 rounded dark:bg-blue-900 dark:text-blue-300","children":"Deep Learning"}],["$","span","Attention Mechanisms",{"className":"bg-blue-100 text-blue-800 text-xs font-medium px-2.5 py-0.5 rounded dark:bg-blue-900 dark:text-blue-300","children":"Attention Mechanisms"}],["$","span","Electronic Health Records",{"className":"bg-blue-100 text-blue-800 text-xs font-medium px-2.5 py-0.5 rounded dark:bg-blue-900 dark:text-blue-300","children":"Electronic Health Records"}]]}]]}],["$","div",null,{"className":"mb-6 pt-4 border-t border-gray-200 dark:border-gray-700","children":[["$","h3",null,{"className":"font-semibold mb-3 text-lg text-gray-700 dark:text-gray-300","children":"Abstract"}],["$","div",null,{"className":"prose dark:prose-invert max-w-none text-sm text-gray-600 dark:text-gray-400 whitespace-pre-wrap","children":"This paper proposes a multi-level, multi-scale attention model utilizing external knowledge to enhance diagnostic code prediction from longitudinal Electronic Health Records (EHRs). The model exploits hierarchical relationships among codes and mimics doctors' reasoning from general to detailed levels, achieving more than 2% F1-score improvement over baselines on the MIMIC-IV dataset."}]]}],["$","div",null,{"className":"space-y-6","children":[["$","div",null,{"className":"mb-6 pt-4 border-t border-gray-200 dark:border-gray-700","children":[["$","h3",null,{"className":"font-semibold mb-3 text-lg bg-red-50 dark:bg-red-900/20 text-red-700 dark:text-red-300 p-2 rounded-md shadow-sm border-l-4 border-red-500 flex items-center","children":[["$","svg",null,{"className":"w-5 h-5 mr-2 text-red-500","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"fillRule":"evenodd","d":"M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7 4a1 1 0 11-2 0 1 1 0 012 0zm-1-9a1 1 0 00-1 1v4a1 1 0 102 0V6a1 1 0 00-1-1z","clipRule":"evenodd"}]}],"Problem"]}],["$","div",null,{"className":"prose dark:prose-invert max-w-none text-gray-600 dark:text-gray-300 pl-4 ml-2 border-l border-gray-200 dark:border-gray-700","children":["$","$L18",null,{"publication":{"id":"multi-scale-and-multi-level-attention-based-on-external-knowledge-in-ehrs","rank":"B","title":"Multi-scale and Multi-level Attention based on External knowledge in EHRs","authors":["Duc Le","Bac Le"],"type":"Conference","isFirstAuthor":true,"highlight":"Proposes a multi-level, multi-scale attention model incorporating external knowledge to improve risk prediction tasks on EHRs.","venue":"Asian Conference on Intelligent Information and Database Systems","abbreviation":"ACIIDS","year":"2024-04-01","abstract":"This paper proposes a multi-level, multi-scale attention model utilizing external knowledge to enhance diagnostic code prediction from longitudinal Electronic Health Records (EHRs). The model exploits hierarchical relationships among codes and mimics doctors' reasoning from general to detailed levels, achieving more than 2% F1-score improvement over baselines on the MIMIC-IV dataset.","problem":[{"type":"text","text":"Deep learning models often fail to exploit hierarchical relationships between diagnostic codes effectively, leading to dispersed attention across a large code space and bias towards frequently occurring codes."},{"type":"text","text":"Current EHR prediction models mostly focus on temporal modeling, ignoring rich external knowledge that could enhance interpretability and accuracy."}],"gap":[{"type":"text","text":"Most existing methods do not sufficiently integrate external medical knowledge like hierarchical code relations (e.g., CCSR structure) into the model's attention mechanism."},{"type":"text","text":"Interpretability is often compromised when trying to optimize model accuracy, creating a gap between model predictions and clinical trust."}],"solution":[{"type":"text","text":"We propose a Multi-scale and Multi-level Attention model that incorporates external hierarchical knowledge (CCSR), organizes diagnostic codes into meaningful levels, and leverages a single feature encoder to model general to detailed correlations."},{"type":"image","url":"https://upload.wikimedia.org/wikipedia/commons/8/88/Transformer.jpg","caption":"Overview of multi-level and multi-scale attention model architecture (illustrative)"},{"type":"text","text":"The model uses Multi-level Attention across CCSR body systems, CCSR categories, and ICD-10 codes, combined with a Multi-scale Feature Synthesizer and Time-aware Dynamic Attention Fusion for enhanced risk prediction."}],"results":[{"type":"text","text":"The model achieves over 2% F1-score improvement compared to strong baselines like HiTANet on the MIMIC-IV dataset, confirming the effectiveness of multi-level hierarchical integration."},{"type":"text","text":"Multi-scale attention fusion improves prediction consistency and interpretability by tracing attention allocation across patient visits and code groups."}],"insights":[{"type":"text","text":"Global attention mechanisms capture long-term health trends, while local attention mechanisms focus on visit-specific details, allowing the model to explain predictions at different abstraction levels."},{"type":"text","text":"Incorporating external hierarchy (CCSR) effectively narrows the model's focus range, making training more stable and predictions more interpretable."}],"contributions":[{"type":"text","text":"1. Introduced a multi-scale, multi-level attention mechanism that improves EHR-based risk prediction accuracy while enhancing interpretability."},{"type":"text","text":"2. Demonstrated the utility of CCSR-based external knowledge in organizing diagnostic codes into hierarchies for better model training."},{"type":"text","text":"3. Provided a comprehensive experimental evaluation showing consistent improvements across multiple metrics compared to existing baselines."}],"topics":["Healthcare AI","Predictive Modeling","Deep Learning","Attention Mechanisms","Electronic Health Records"],"doi":null,"links":{"website":null,"youtube_demo":null,"github_repository":"https://github.com/Haru-Lab-Space/MsTA","view_publication":"https://ceur-ws.org/Vol-3658/paper5.pdf"},"citationCount":0,"citationFormat":"Le, D., & Le, B. (2024). Multi-scale and Multi-level Attention based on External knowledge in EHRs. International Conference on Multimedia Information Processing and Retrieval (MIPR) 2024.","images":[],"technologies":["PyTorch","Transformer","Attention Mechanism","Healthcare Data Analysis"],"references":{"1":"Ye, M., et al. MedPath: Augmenting Health Risk Prediction via Medical Knowledge Paths. WWW 2021.","2":"Choi, E., et al. GRAM: Graph-Based Attention Model for Healthcare Representation Learning. KDD 2017.","3":"Luo, J., et al. HiTANet: Hierarchical Time-Aware Attention Networks for Risk Prediction. KDD 2020."}},"section":"problem"}]}]]}],["$","div",null,{"className":"mb-6 pt-4 border-t border-gray-200 dark:border-gray-700","children":[["$","h3",null,{"className":"font-semibold mb-3 text-lg bg-orange-50 dark:bg-orange-900/20 text-orange-700 dark:text-orange-300 p-2 rounded-md shadow-sm border-l-4 border-orange-500 flex items-center","children":[["$","svg",null,{"className":"w-5 h-5 mr-2 text-orange-500","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"fillRule":"evenodd","d":"M5 2a1 1 0 011 1v1h1a1 1 0 010 2H6v1a1 1 0 01-2 0V6H3a1 1 0 010-2h1V3a1 1 0 011-1zm0 10a1 1 0 011 1v1h1a1 1 0 110 2H6v1a1 1 0 11-2 0v-1H3a1 1 0 110-2h1v-1a1 1 0 011-1zM12 2a1 1 0 01.967.744L14.146 7.2 17.5 9.134a1 1 0 010 1.732l-3.354 1.935-1.18 4.455a1 1 0 01-1.933 0L9.854 12.8 6.5 10.866a1 1 0 010-1.732l3.354-1.935 1.18-4.455A1 1 0 0112 2z","clipRule":"evenodd"}]}],"Research Gap"]}],["$","div",null,{"className":"prose dark:prose-invert max-w-none text-gray-600 dark:text-gray-300 pl-4 ml-2 border-l border-gray-200 dark:border-gray-700","children":["$","$L18",null,{"publication":"$a:props:children:props:children:6:props:children:0:props:children:1:props:children:props:publication","section":"gap"}]}]]}],["$","div",null,{"className":"mb-6 pt-4 border-t border-gray-200 dark:border-gray-700","children":[["$","h3",null,{"className":"font-semibold mb-3 text-lg bg-blue-50 dark:bg-blue-900/20 text-blue-700 dark:text-blue-300 p-2 rounded-md shadow-sm border-l-4 border-blue-500 flex items-center","children":[["$","svg",null,{"className":"w-5 h-5 mr-2 text-blue-500","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"d":"M11 3a1 1 0 10-2 0v1a1 1 0 102 0V3zM15.657 5.757a1 1 0 00-1.414-1.414l-.707.707a1 1 0 001.414 1.414l.707-.707zM18 10a1 1 0 01-1 1h-1a1 1 0 110-2h1a1 1 0 011 1zM5.05 6.464A1 1 0 106.464 5.05l-.707-.707a1 1 0 00-1.414 1.414l.707.707zM5 10a1 1 0 01-1 1H3a1 1 0 110-2h1a1 1 0 011 1zM8 16v-1h4v1a2 2 0 11-4 0zM12 14c.015-.34.208-.646.477-.859a4 4 0 10-4.954 0c.27.213.462.519.476.859h4.002z"}]}],"Proposed Method"]}],["$","div",null,{"className":"prose dark:prose-invert max-w-none text-gray-600 dark:text-gray-300 pl-4 ml-2 border-l border-gray-200 dark:border-gray-700","children":["$","$L18",null,{"publication":"$a:props:children:props:children:6:props:children:0:props:children:1:props:children:props:publication","section":"solution"}]}]]}],["$","div",null,{"className":"mb-6 pt-4 border-t border-gray-200 dark:border-gray-700","children":[["$","h3",null,{"className":"font-semibold mb-3 text-lg bg-green-50 dark:bg-green-900/20 text-green-700 dark:text-green-300 p-2 rounded-md shadow-sm border-l-4 border-green-500 flex items-center","children":[["$","svg",null,{"className":"w-5 h-5 mr-2 text-green-500","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"fillRule":"evenodd","d":"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z","clipRule":"evenodd"}]}],"Key Results"]}],["$","div",null,{"className":"prose dark:prose-invert max-w-none text-gray-600 dark:text-gray-300 pl-4 ml-2 border-l border-gray-200 dark:border-gray-700","children":["$","$L18",null,{"publication":"$a:props:children:props:children:6:props:children:0:props:children:1:props:children:props:publication","section":"results"}]}]]}],["$","div",null,{"className":"mb-6 pt-4 border-t border-gray-200 dark:border-gray-700","children":[["$","h3",null,{"className":"font-semibold mb-3 text-lg bg-yellow-50 dark:bg-yellow-900/20 text-yellow-700 dark:text-yellow-300 p-2 rounded-md shadow-sm border-l-4 border-yellow-500 flex items-center","children":[["$","svg",null,{"className":"w-5 h-5 mr-2 text-yellow-500","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"d":"M11 3a1 1 0 10-2 0v1a1 1 0 102 0V3zM15.657 5.757a1 1 0 00-1.414-1.414l-.707.707a1 1 0 001.414 1.414l.707-.707zM18 10a1 1 0 01-1 1h-1a1 1 0 110-2h1a1 1 0 011 1zM5.05 6.464A1 1 0 106.464 5.05l-.707-.707a1 1 0 00-1.414 1.414l.707.707zM5 10a1 1 0 01-1 1H3a1 1 0 110-2h1a1 1 0 011 1zM8 16v-1h4v1a2 2 0 11-4 0zM12 14c.015-.34.208-.646.477-.859a4 4 0 10-4.954 0c.27.213.462.519.476.859h4.002z"}]}],"Insights & Observations"]}],["$","div",null,{"className":"prose dark:prose-invert max-w-none text-gray-600 dark:text-gray-300 pl-4 ml-2 border-l border-gray-200 dark:border-gray-700","children":["$","$L18",null,{"publication":"$a:props:children:props:children:6:props:children:0:props:children:1:props:children:props:publication","section":"insights"}]}]]}],["$","div",null,{"className":"mb-6 pt-4 border-t border-gray-200 dark:border-gray-700","children":[["$","h3",null,{"className":"font-semibold mb-3 text-lg bg-purple-50 dark:bg-purple-900/20 text-purple-700 dark:text-purple-300 p-2 rounded-md shadow-sm border-l-4 border-purple-500 flex items-center","children":[["$","svg",null,{"className":"w-5 h-5 mr-2 text-purple-500","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"d":"M7 3a1 1 0 000 2h6a1 1 0 100-2H7zM4 7a1 1 0 011-1h10a1 1 0 110 2H5a1 1 0 01-1-1zM2 11a2 2 0 012-2h12a2 2 0 012 2v4a2 2 0 01-2 2H4a2 2 0 01-2-2v-4z"}]}],"Contributions & Future Work"]}],["$","div",null,{"className":"prose dark:prose-invert max-w-none text-gray-600 dark:text-gray-300 pl-4 ml-2 border-l border-gray-200 dark:border-gray-700","children":["$","$L18",null,{"publication":"$a:props:children:props:children:6:props:children:0:props:children:1:props:children:props:publication","section":"contributions"}]}]]}]]}],["$","div",null,{"className":"mt-8 mb-6 pt-4 border-t border-gray-200 dark:border-gray-700","children":[["$","h3",null,{"className":"font-semibold mb-4 text-lg text-gray-700 dark:text-gray-300","children":"Links"}],["$","div",null,{"className":"grid grid-cols-1 sm:grid-cols-2 gap-4","children":[["$","a",null,{"href":"https://ceur-ws.org/Vol-3658/paper5.pdf","target":"_blank","rel":"noopener noreferrer","className":"flex items-center p-3 text-blue-600 hover:text-blue-800 dark:text-blue-400 dark:hover:text-blue-300 bg-blue-50 dark:bg-blue-900/20 rounded-lg transition-colors","children":[["$","svg",null,{"className":"w-5 h-5 mr-2","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"d":"M9 4.804A7.968 7.968 0 005.5 4c-1.255 0-2.443.29-3.5.804v10A7.969 7.969 0 015.5 14c1.669 0 3.218.51 4.5 1.385A7.962 7.962 0 0114.5 14c1.255 0 2.443.29 3.5.804v-10A7.968 7.968 0 0014.5 4c-1.255 0-2.443.29-3.5.804V12a1 1 0 11-2 0V4.804z"}]}],"View Publication"]}],null,null,["$","a",null,{"href":"https://github.com/Haru-Lab-Space/MsTA","target":"_blank","rel":"noopener noreferrer","className":"flex items-center p-3 text-gray-700 hover:text-gray-900 dark:text-gray-300 dark:hover:text-white bg-gray-100 dark:bg-gray-800 rounded-lg transition-colors","children":[["$","svg",null,{"className":"w-5 h-5 mr-2","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"fillRule":"evenodd","d":"M10 0C4.477 0 0 4.484 0 10.017c0 4.425 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.008-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.029-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0110 4.844c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.027 2.747-1.027.546 1.379.202 2.398.1 2.651.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.019 10.019 0 0020 10.017C20 4.484 15.522 0 10 0z","clipRule":"evenodd"}]}],"GitHub Repository"]}]]}]]}],false,["$","div",null,{"className":"mt-8 mb-6 pt-4 border-t border-gray-200 dark:border-gray-700","children":[["$","h3",null,{"className":"font-semibold mb-4 text-lg text-gray-700 dark:text-gray-300 flex items-center","children":[["$","svg",null,{"className":"w-5 h-5 mr-2","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"d":"M9 4.804A7.968 7.968 0 005.5 4c-1.255 0-2.443.29-3.5.804v10A7.969 7.969 0 015.5 14c1.669 0 3.218.51 4.5 1.385A7.962 7.962 0 0114.5 14c1.255 0 2.443.29 3.5.804v-10A7.968 7.968 0 0014.5 4c-1.255 0-2.443.29-3.5.804V12a1 1 0 11-2 0V4.804z"}]}],"References"]}],["$","ol",null,{"className":"space-y-3 list-decimal list-inside text-gray-700 dark:text-gray-300","children":[["$","li","1",{"id":"reference-1","className":"pl-2 py-2 border-l-2 border-gray-300 dark:border-gray-600 bg-gray-50 dark:bg-gray-800/30 rounded-r-md scroll-mt-24 hover:bg-gray-100 dark:hover:bg-gray-800/50 transition-colors duration-200","children":"Ye, M., et al. MedPath: Augmenting Health Risk Prediction via Medical Knowledge Paths. WWW 2021."}],["$","li","2",{"id":"reference-2","className":"pl-2 py-2 border-l-2 border-gray-300 dark:border-gray-600 bg-gray-50 dark:bg-gray-800/30 rounded-r-md scroll-mt-24 hover:bg-gray-100 dark:hover:bg-gray-800/50 transition-colors duration-200","children":"Choi, E., et al. GRAM: Graph-Based Attention Model for Healthcare Representation Learning. KDD 2017."}],["$","li","3",{"id":"reference-3","className":"pl-2 py-2 border-l-2 border-gray-300 dark:border-gray-600 bg-gray-50 dark:bg-gray-800/30 rounded-r-md scroll-mt-24 hover:bg-gray-100 dark:hover:bg-gray-800/50 transition-colors duration-200","children":"Luo, J., et al. HiTANet: Hierarchical Time-Aware Attention Networks for Risk Prediction. KDD 2020."}]]}]]}],["$","div",null,{"className":"mt-8 mb-6 pt-4 border-t border-gray-200 dark:border-gray-700","children":[["$","h3",null,{"className":"font-semibold mb-3 text-lg text-gray-700 dark:text-gray-300","children":"Tags/Technologies:"}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","PyTorch",{"className":"bg-green-100 text-green-800 text-xs font-medium px-2.5 py-0.5 rounded dark:bg-green-900 dark:text-green-300","children":"PyTorch"}],["$","span","Transformer",{"className":"bg-green-100 text-green-800 text-xs font-medium px-2.5 py-0.5 rounded dark:bg-green-900 dark:text-green-300","children":"Transformer"}],["$","span","Attention Mechanism",{"className":"bg-green-100 text-green-800 text-xs font-medium px-2.5 py-0.5 rounded dark:bg-green-900 dark:text-green-300","children":"Attention Mechanism"}],["$","span","Healthcare Data Analysis",{"className":"bg-green-100 text-green-800 text-xs font-medium px-2.5 py-0.5 rounded dark:bg-green-900 dark:text-green-300","children":"Healthcare Data Analysis"}]]}]]}],["$","$L19",null,{"citationText":"Le, D., & Le, B. (2024). Multi-scale and Multi-level Attention based on External knowledge in EHRs. International Conference on Multimedia Information Processing and Retrieval (MIPR) 2024.","citationCount":0}],["$","div",null,{"className":"mt-8","children":null}],["$","div",null,{"className":"mt-0","children":null}]]}]}]
